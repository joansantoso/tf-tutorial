{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxao5Xd61Gsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c9d3e2-2590-4759-c4e7-99276219fd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-24 16:52:02--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-08-24 16:52:02--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-08-24 16:52:02--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-08-24 16:54:41 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "--2023-08-24 16:54:41--  https://www.clips.uantwerpen.be/conll2000/chunking/train.txt.gz\n",
            "Resolving www.clips.uantwerpen.be (www.clips.uantwerpen.be)... 146.175.13.81\n",
            "Connecting to www.clips.uantwerpen.be (www.clips.uantwerpen.be)|146.175.13.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 611540 (597K) [application/x-gzip]\n",
            "Saving to: ‘train.txt.gz’\n",
            "\n",
            "train.txt.gz        100%[===================>] 597.21K   815KB/s    in 0.7s    \n",
            "\n",
            "2023-08-24 16:54:43 (815 KB/s) - ‘train.txt.gz’ saved [611540/611540]\n",
            "\n",
            "--2023-08-24 16:54:43--  https://www.clips.uantwerpen.be/conll2000/chunking/test.txt.gz\n",
            "Resolving www.clips.uantwerpen.be (www.clips.uantwerpen.be)... 146.175.13.81\n",
            "Connecting to www.clips.uantwerpen.be (www.clips.uantwerpen.be)|146.175.13.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139551 (136K) [application/x-gzip]\n",
            "Saving to: ‘test.txt.gz’\n",
            "\n",
            "test.txt.gz         100%[===================>] 136.28K   311KB/s    in 0.4s    \n",
            "\n",
            "2023-08-24 16:54:44 (311 KB/s) - ‘test.txt.gz’ saved [139551/139551]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!wget https://www.clips.uantwerpen.be/conll2000/chunking/train.txt.gz\n",
        "!wget https://www.clips.uantwerpen.be/conll2000/chunking/test.txt.gz\n",
        "\n",
        "!unzip -q glove.6B.zip\n",
        "!gzip -d /content/train.txt.gz\n",
        "!gzip -d /content/test.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "gjJIkWPLL8he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"/content/glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta4_EHyhLa1P",
        "outputId": "bc587749-6706-4f75-d086-ad88b3f88fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_file = open('/content/train.txt')\n",
        "all_text_train = all_text_file.read()\n",
        "all_text_train_splitted = all_text_train.split('\\n\\n')\n",
        "\n",
        "all_text_file = open('/content/test.txt')\n",
        "all_text_test = all_text_file.read()\n",
        "all_text_test_splitted = all_text_test.split('\\n\\n')"
      ],
      "metadata": {
        "id": "1Zd4raOcVMoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_DIMENSION = 100\n",
        "UNK_RAND_TOKEN = np.random.randn(GLOVE_DIMENSION)\n",
        "MAX_LEN = np.array([len(text_split_now.split('\\n')) for text_split_now in all_text_train_splitted ]).max()\n",
        "\n",
        "class_names_dictionary_temp = {}\n",
        "for sentence in all_text_train_splitted :\n",
        "  split_sentence = sentence.split('\\n')\n",
        "  if len(split_sentence) > 2 :\n",
        "    for row in split_sentence :\n",
        "      col_now = row.split(' ')\n",
        "      if not (col_now[2] in class_names_dictionary_temp) :\n",
        "        class_names_dictionary_temp[col_now[2]] = len(class_names_dictionary_temp)\n",
        "\n",
        "tag_name_bio = []\n",
        "tag_name_other = []\n",
        "for key in class_names_dictionary_temp :\n",
        "  if len(key.split('-')) > 1 :\n",
        "    if not (key.split('-')[1] in tag_name_bio) :\n",
        "      tag_name_bio.append(key.split('-')[1])\n",
        "  else :\n",
        "    tag_name_other.append(key)\n",
        "\n",
        "class_names_dictionary = {'[PAD]':0}\n",
        "for tag_now in tag_name_bio :\n",
        "  class_names_dictionary[\"B-\" + tag_now] =  len(class_names_dictionary)\n",
        "  class_names_dictionary[\"I-\" + tag_now] =  len(class_names_dictionary)\n",
        "for tag_now in tag_name_other :\n",
        "  class_names_dictionary[tag_now] =  len(class_names_dictionary)\n",
        "\n",
        "class_names_dictionary_reversed = {class_names_dictionary[key_now]:key_now for key_now in class_names_dictionary}"
      ],
      "metadata": {
        "id": "qgZTmA1liBEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(splitted_text_data) :\n",
        "  samples = []\n",
        "  labels = []\n",
        "  all_raw_text = []\n",
        "\n",
        "  for sentence in splitted_text_data :\n",
        "    split_sentence = sentence.split('\\n')\n",
        "    if len(split_sentence) > 2 :\n",
        "      x_now = []\n",
        "      y_now = []\n",
        "      raw_text = \"\"\n",
        "      for row in split_sentence :\n",
        "        col_now = row.split(' ')\n",
        "        col_now[0] = col_now[0].lower()\n",
        "        if col_now[0] == '-LRB-':\n",
        "          col_now[0] = '('\n",
        "        elif col_now[0] == '-RRB-':\n",
        "          col_now[0] = ')'\n",
        "\n",
        "        raw_text = raw_text + col_now[0] + \" \"\n",
        "\n",
        "        if col_now[0] in embeddings_index :\n",
        "          x_now.append(embeddings_index[col_now[0]])\n",
        "        else :\n",
        "          x_now.append(UNK_RAND_TOKEN)\n",
        "        y_now.append(class_names_dictionary[col_now[2]])\n",
        "      x_now = np.stack(x_now)\n",
        "      y_now = np.array(y_now + [0]*int((MAX_LEN - len(x_now))))\n",
        "      y_now_one_hot = np.zeros((MAX_LEN,len(class_names_dictionary)))\n",
        "      y_now_one_hot[np.arange(MAX_LEN), y_now] = 1\n",
        "\n",
        "      x_now = np.pad(x_now,((0,MAX_LEN - len(x_now)),(0,0)),mode=\"constant\")\n",
        "\n",
        "      all_raw_text.append(str(raw_text).strip() )\n",
        "      samples.append(x_now)\n",
        "      labels.append(y_now_one_hot)\n",
        "  samples = np.stack(samples)\n",
        "  labels = np.stack(labels)\n",
        "\n",
        "  return samples, labels, all_raw_text"
      ],
      "metadata": {
        "id": "1fQQDCLsX06C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERModel(keras.Model):\n",
        "  def __init__(\n",
        "      self, num_tags, embed_dim=100, hidden_dim = 128\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.bidirectional_1 = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(hidden_dim//2, return_sequences=True)\n",
        "      )\n",
        "    self.bidirectional_2 = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(hidden_dim//2, return_sequences=True)\n",
        "      )\n",
        "\n",
        "    self.dense1 = keras.layers.Dense(num_tags)\n",
        "    self.softmax = tf.keras.layers.Softmax(axis = -1)\n",
        "\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    yhat = self.bidirectional_1(inputs)\n",
        "    yhat = self.bidirectional_2(yhat)\n",
        "    yhat = self.dense1(yhat)\n",
        "    yhat = self.softmax(yhat)\n",
        "\n",
        "    return yhat\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training=True)\n",
        "      loss = self.compute_loss(y=y, y_pred=y_pred)\n",
        "\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    for metric in self.metrics:\n",
        "      if metric.name == \"loss\":\n",
        "        metric.update_state(loss)\n",
        "      else:\n",
        "        metric.update_state(y, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics}\n"
      ],
      "metadata": {
        "id": "x5beJwRacHEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNonPaddingTokenLoss(keras.losses.Loss):\n",
        "  def __init__(self, name=\"custom_ner_loss\"):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "\n",
        "    loss = -y_true*tf.math.log(y_pred)\n",
        "    mask = tf.cast((y_true[:,:,0:1] == 0), dtype=tf.float32)\n",
        "    loss = loss * mask\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "loss_function = CustomNonPaddingTokenLoss()\n"
      ],
      "metadata": {
        "id": "EP1s24OCcnxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_train, labels_train, all_raw_text_train = preprocess_data(all_text_train_splitted)\n",
        "samples_test, labels_test, all_raw_text_test = preprocess_data(all_text_test_splitted)"
      ],
      "metadata": {
        "id": "Ei_nRWzvqvvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = CustomNonPaddingTokenLoss()\n",
        "\n",
        "ner_model = NERModel(len(class_names_dictionary))\n",
        "ner_model.build((None, MAX_LEN,GLOVE_DIMENSION))\n",
        "ner_model.call(tf.keras.layers.Input(shape = (MAX_LEN, GLOVE_DIMENSION)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOqvsKIWhk-S",
        "outputId": "e6eb99de-8fb0-421c-a77e-d768ce76fc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 78, 24) dtype=float32 (created by layer 'softmax')>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhN3cR5sWFM",
        "outputId": "ded0195d-44fa-49e2-c372-69fd41cf20d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ner_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 78, 128)          84480     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 78, 128)          98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 78, 24)            3096      \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 78, 24)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,392\n",
            "Trainable params: 186,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.compile(optimizer=\"adam\", loss=loss_function)"
      ],
      "metadata": {
        "id": "vznPKIlqtpru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.fit(samples_train,labels_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBkjUcD3sWOU",
        "outputId": "2934a6a1-d73a-4991-ee1d-72771eb3e35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 39/278 [===>..........................] - ETA: 47s - loss: 1.9364"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(sentence) :\n",
        "  all_word = sentence.split(' ')\n",
        "\n",
        "  x_now = []\n",
        "  y_now = []\n",
        "  raw_text = \"\"\n",
        "  for word in all_word :\n",
        "    word = word.lower()\n",
        "    if word == '-LRB-':\n",
        "      word = '('\n",
        "    elif word == '-RRB-':\n",
        "      word = ')'\n",
        "\n",
        "    if word in embeddings_index :\n",
        "      x_now.append(embeddings_index[word])\n",
        "    else :\n",
        "      x_now.append(UNK_RAND_TOKEN)\n",
        "\n",
        "  x_now = np.stack(x_now)\n",
        "  return x_now"
      ],
      "metadata": {
        "id": "czvWTGSgwQr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tag(model,sentence) :\n",
        "  sentence_check_feature = preprocess_text(sentence)\n",
        "  sentence_check_feature = np.stack([sentence_check_feature])\n",
        "  tag_list = np.argmax(ner_model(sentence_check_feature,training=False).numpy(),-1)[0]\n",
        "\n",
        "  return tag_list"
      ],
      "metadata": {
        "id": "zTXVwTto8eCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_tag(tag_list) :\n",
        "  return [class_names_dictionary_reversed[tag] for tag in tag_list]"
      ],
      "metadata": {
        "id": "cHYYuhGr9WFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_check_test = 0\n",
        "text_now = all_raw_text_test[idx_check_test]\n",
        "\n",
        "tag_list = get_tag(ner_model,text_now)\n",
        "decoded_tag = decode_tag(tag_list)\n",
        "\n",
        "print(\"text :\", text_now)\n",
        "print(\"tags :\", decoded_tag)\n",
        "print(\"real tags :\", decode_tag(labels_test[idx_check_test].argmax(-1)[0:len(text_now.split(' '))]  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW1wq6KtzrR6",
        "outputId": "72edd096-be71-41ab-cddc-5cf74187f73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text : rockwell international corp. 's tulsa unit said it signed a tentative agreement extending its contract with boeing co. to provide structural parts for boeing 's 747 jetliners .\n",
            "tags : ['B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
            "real tags : ['B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_now = \"My name is Andi .\"\n",
        "\n",
        "tag_list = get_tag(ner_model,text_now)\n",
        "decoded_tag = decode_tag(tag_list)\n",
        "print(decoded_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6RaIwMy-a3J",
        "outputId": "df6e28c4-3378-4b38-e57f-57290f58e3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-NP', 'I-NP', 'B-VP', 'B-NP', 'O']\n"
          ]
        }
      ]
    }
  ]
}